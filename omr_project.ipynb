{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f7c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.6.0.66 in c:\\users\\user\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python==4.6.0.66) (1.22.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python==4.6.0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa241e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6417fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the four corners are identified, we will do a four-point\n",
    "# perspective transform such that the outmost points of each\n",
    "# corner map to a TRANSF_SIZE x TRANSF_SIZE square image.\n",
    "TRANSF_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e98912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer sheet properties.\n",
    "N_QUESTIONS = 10\n",
    "ANSWER_SHEET_WIDTH = 740\n",
    "ANSWER_SHEET_HEIGHT = 1049\n",
    "\n",
    "ANSWER_PATCH_HEIGHT = 50\n",
    "ANSWER_PATCH_HEIGHT_WITH_MARGIN = 80\n",
    "ANSWER_PATCH_LEFT_MARGIN = 200\n",
    "ANSWER_PATCH_RIGHT_MARGIN = 90\n",
    "FIRST_ANSWER_PATCH_TOP_Y = 200\n",
    "\n",
    "ALTERNATIVE_HEIGHT = 50\n",
    "ALTERNATIVE_WIDTH = 50\n",
    "ALTERNATIVE_WIDTH_WITH_MARGIN = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac73d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contour_features(contour):\n",
    "    \"\"\"Calculates interesting properties (features) of a contour.\n",
    "\n",
    "    We use these features to match shapes (contours). In this script,\n",
    "    we are interested in finding shapes in our input image that look like\n",
    "    a corner. We do that by calculating the features for many contours\n",
    "    in the input image and comparing these to the features of the corner\n",
    "    contour. By design, we know exactly what the features of the real corner\n",
    "    contour look like - check out the calculate_corner_features function.\n",
    "\n",
    "    It is crucial for these features to be invariant both to scale and rotation.\n",
    "    In other words, we know that a corner is a corner regardless of its size\n",
    "    or rotation. In the past, this script implemented its own features, but\n",
    "    OpenCV offers much more robust scale and rotational invariant features\n",
    "    out of the box - the Hu moments.\n",
    "    \"\"\"\n",
    "    moments = cv2.moments(contour)\n",
    "    return cv2.HuMoments(moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a400426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corner_features():\n",
    "    \"\"\"Calculates the array of features for the corner contour.\n",
    "    In practice, this can be pre-calculated, as the corners are constant\n",
    "    and independent from the inputs.\n",
    "\n",
    "    We load the img/corner.png file, which contains a single corner, so we\n",
    "    can reliably extract its features. We will use these features to look for\n",
    "    contours in our input image that look like a corner.\n",
    "    \"\"\"\n",
    "    corner_img = cv2.imread('img/corner.png')\n",
    "    corner_img_gray = cv2.cvtColor(corner_img, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        corner_img_gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # We expect to see only two contours:\n",
    "    # - The \"outer\" contour, which wraps the whole image, at hierarchy level 0\n",
    "    # - The corner contour, which we are looking for, at hierarchy level 1\n",
    "    # If in trouble, one way to check what's happening is to draw the found contours\n",
    "    # with cv2.drawContours(corner_img, contours, -1, (255, 0, 0)) and try and find\n",
    "    # the correct corner contour by drawing one contour at a time. Ideally, this\n",
    "    # would not be done at runtime.\n",
    "    if len(contours) != 2:\n",
    "        raise RuntimeError(\n",
    "            'Did not find the expected contours when looking for the corner')\n",
    "\n",
    "    # Following our assumptions as stated above, we take the contour that has a parent\n",
    "    # contour (that is, it is _not_ the outer contour) to be the corner contour.\n",
    "    # If in trouble, verify that this contour is the corner contour with\n",
    "    # cv2.drawContours(corner_img, [corner_contour], -1, (255, 0, 0))\n",
    "    corner_contour = next(ct\n",
    "                          for i, ct in enumerate(contours)\n",
    "                          if hierarchy[0][i][3] != -1)\n",
    "\n",
    "    return calculate_contour_features(corner_contour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e946207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(im):\n",
    "    \"\"\"Converts `im` to black and white.\n",
    "\n",
    "    Applying a threshold to a grayscale image will make every pixel either\n",
    "    fully black or fully white. Before doing so, a common technique is to\n",
    "    get rid of noise (or super high frequency color change) by blurring the\n",
    "    grayscale image with a Gaussian filter.\"\"\"\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Filter the grayscale image with a 3x3 kernel\n",
    "    blurred = cv2.GaussianBlur(im_gray, (3, 3), 0)\n",
    "\n",
    "    # Applies a Gaussian adaptive thresholding. In practice, adaptive thresholding\n",
    "    # seems to work better than appling a single, global threshold to the image.\n",
    "    # This is particularly important if there could be shadows or non-uniform\n",
    "    # lighting on the answer sheet. In those scenarios, using a global thresholding\n",
    "    # technique might yield paricularly bad results.\n",
    "    # The choice of the parameters blockSize = 77 and C = 10 is as much as an art\n",
    "    # as a science and domain-dependand.\n",
    "    # In practice, you might want to try different  values for your specific answer\n",
    "    # sheet.\n",
    "    return cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 77, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c82edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approx_contour(contour, tol=.01):\n",
    "    \"\"\"Gets rid of 'useless' points in the contour.\"\"\"\n",
    "    epsilon = tol * cv2.arcLength(contour, True)\n",
    "    return cv2.approxPolyDP(contour, epsilon, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58bddcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(image_gray):\n",
    "    contours, _ = cv2.findContours(\n",
    "        image_gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return map(get_approx_contour, contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52c765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners(contours):\n",
    "    \"\"\"Returns the 4 contours that look like a corner the most.\n",
    "\n",
    "    In the real world, we cannot assume that the corners will always be present,\n",
    "    and we likely need to decide how good is good enough for contour to\n",
    "    look like a corner.\n",
    "    This is essentially a classification problem. A good approach would be\n",
    "    to train a statistical classifier model and apply it here. In our little\n",
    "    exercise, we assume the corners are necessarily there.\"\"\"\n",
    "    corner_features = calculate_corner_features()\n",
    "    return sorted(\n",
    "        contours,\n",
    "        key=lambda c: features_distance(\n",
    "                corner_features,\n",
    "                calculate_contour_features(c)))[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12fff25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_rect(contour):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    return np.int0(box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784bdc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_distance(f1, f2):\n",
    "    return np.linalg.norm(np.array(f1) - np.array(f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737cf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_point(point, img, radius=5, color=(0, 0, 255)):\n",
    "    cv2.circle(img, tuple(point), radius, color, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec930a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(contour):\n",
    "    m = cv2.moments(contour)\n",
    "    x = int(m[\"m10\"] / m[\"m00\"])\n",
    "    y = int(m[\"m01\"] / m[\"m00\"])\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0098b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points_counter_clockwise(points):\n",
    "    origin = np.mean(points, axis=0)\n",
    "\n",
    "    def positive_angle(p):\n",
    "        x, y = p - origin\n",
    "        ang = np.arctan2(y, x)\n",
    "        return 2 * np.pi + ang if ang < 0 else ang\n",
    "\n",
    "    return sorted(points, key=positive_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "534f2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outmost_points(contours):\n",
    "    all_points = np.concatenate(contours)\n",
    "    return get_bounding_rect(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cadee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(img, points):\n",
    "    \"\"\"Applies a 4-point perspective transformation in `img` so that `points`\n",
    "    are the new corners.\"\"\"\n",
    "    source = np.array(\n",
    "        points,\n",
    "        dtype=\"float32\")\n",
    "\n",
    "    dest = np.array([\n",
    "        [TRANSF_SIZE, TRANSF_SIZE],\n",
    "        [0, TRANSF_SIZE],\n",
    "        [0, 0],\n",
    "        [TRANSF_SIZE, 0]],\n",
    "        dtype=\"float32\")\n",
    "\n",
    "    transf = cv2.getPerspectiveTransform(source, dest)\n",
    "    warped = cv2.warpPerspective(img, transf, (TRANSF_SIZE, TRANSF_SIZE))\n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c05296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sheet_coord_to_transf_coord(x, y):\n",
    "    return list(map(lambda n: int(np.round(n)), (\n",
    "        TRANSF_SIZE * x / ANSWER_SHEET_WIDTH,\n",
    "        TRANSF_SIZE * y / ANSWER_SHEET_HEIGHT\n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5f713c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_patch(transf, question_index):\n",
    "    \"\"\"Exracts a region of interest (ROI) of a single question.\"\"\"\n",
    "    # Top left of question patch q_number\n",
    "    tl = sheet_coord_to_transf_coord(\n",
    "        ANSWER_PATCH_LEFT_MARGIN,\n",
    "        FIRST_ANSWER_PATCH_TOP_Y + ANSWER_PATCH_HEIGHT_WITH_MARGIN * question_index\n",
    "    )\n",
    "\n",
    "    # Bottom right of question patch q_number\n",
    "    br = sheet_coord_to_transf_coord(\n",
    "        ANSWER_SHEET_WIDTH - ANSWER_PATCH_RIGHT_MARGIN,\n",
    "        FIRST_ANSWER_PATCH_TOP_Y +\n",
    "        ANSWER_PATCH_HEIGHT +\n",
    "        ANSWER_PATCH_HEIGHT_WITH_MARGIN * question_index\n",
    "    )\n",
    "    return transf[tl[1]:br[1], tl[0]:br[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dff2c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_patches(transf):\n",
    "    for i in range(N_QUESTIONS):\n",
    "        yield get_question_patch(transf, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7178a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alternative_patches(question_patch):\n",
    "    for i in range(5):\n",
    "        x0, _ = sheet_coord_to_transf_coord(ALTERNATIVE_WIDTH_WITH_MARGIN * i, 0)\n",
    "        x1, _ = sheet_coord_to_transf_coord(ALTERNATIVE_WIDTH +\n",
    "                                            ALTERNATIVE_WIDTH_WITH_MARGIN * i, 0)\n",
    "        yield question_patch[:, x0:x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "effa3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_marked_alternative(question_patch, index):\n",
    "    cx, cy = sheet_coord_to_transf_coord(\n",
    "        ALTERNATIVE_WIDTH * (2 * index + .5),\n",
    "        ALTERNATIVE_HEIGHT / 2)\n",
    "    draw_point((cx, cy), question_patch, radius=5, color=(255, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cefe238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marked_alternative(alternative_patches):\n",
    "    \"\"\"Decides which alternative is marked, if any.\n",
    "\n",
    "    Given a list of alternative patches, we need to decide which one,\n",
    "    if any, is marked. Here, we do a simple, hacky heuristic: the\n",
    "    alternative patch with lowest brightness (darker), is marked if\n",
    "    it is sufficiently darker than the _second_ darker alternative\n",
    "    patch.\n",
    "\n",
    "    In practice, a more robust, data-driven model is necessary.\"\"\"\n",
    "    means = list(map(np.mean, alternative_patches))\n",
    "    sorted_means = sorted(means)\n",
    "\n",
    "    # Simple heuristic\n",
    "    if sorted_means[0]/sorted_means[1] > .7:\n",
    "        return None\n",
    "\n",
    "    return np.argmin(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92f98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter(alt_index):\n",
    "    return [\"A\", \"B\", \"C\", \"D\", \"E\"][alt_index] if alt_index is not None else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43acd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(source_file):\n",
    "    \"\"\"Runs the full pipeline:\n",
    "\n",
    "    - Loads input image\n",
    "    - Normalizes image\n",
    "    - Finds contours\n",
    "    - Finds corners among all contours\n",
    "    - Finds 'outmost' points of all corners\n",
    "    - Applies perpsective transform to get a bird's eye view\n",
    "    - Scans each line for the marked alternative\n",
    "    \"\"\"\n",
    "    im_orig = cv2.imread(source_file)\n",
    "\n",
    "    im_normalized = normalize(im_orig)\n",
    "\n",
    "    contours = get_contours(im_normalized)\n",
    "\n",
    "    corners = get_corners(contours)\n",
    "\n",
    "    cv2.drawContours(im_orig, corners, -1, (0, 255, 0), 3)\n",
    "\n",
    "    outmost = sort_points_counter_clockwise(get_outmost_points(corners))\n",
    "\n",
    "    color_transf = perspective_transform(im_orig, outmost)\n",
    "    normalized_transf = perspective_transform(im_normalized, outmost)\n",
    "\n",
    "    answers = []\n",
    "    for i, q_patch in enumerate(get_question_patches(normalized_transf)):\n",
    "        alt_index = get_marked_alternative(get_alternative_patches(q_patch))\n",
    "\n",
    "        if alt_index is not None:\n",
    "            color_q_patch = get_question_patch(color_transf, i)\n",
    "            draw_marked_alternative(color_q_patch, alt_index)\n",
    "\n",
    "        answers.append(get_letter(alt_index))\n",
    "\n",
    "    return answers, color_transf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c03eb81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --input INPUT [--output OUTPUT] [--show]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --input\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--input\",\n",
    "        help=\"Input image filename\",\n",
    "        required=True,\n",
    "        type=str)\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        help=\"Output image filename\",\n",
    "        type=str)\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--show\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Displays annotated image\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    answers, im = get_answers(args.input)\n",
    "\n",
    "    for i, answer in enumerate(answers):\n",
    "        print(\"Q{}: {}\".format(i + 1, answer))\n",
    "\n",
    "    if args.output:\n",
    "        cv2.imwrite(args.output, im)\n",
    "        print('Wrote image to {}.'.format(args.output))\n",
    "\n",
    "    if args.show:\n",
    "        cv2.imshow('Annotated image', im)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562add97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
